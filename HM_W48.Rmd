---
title: 'Text mining, sentiment analysis, and visualization'
date: 'created on 2 december 2022 and updated `r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)

library(tidyverse)
library(here)

# For text mining:
library(pdftools)
library(tidytext)
library(textdata) 
library(ggwordcloud)

# Note - Before lab:
# Attach tidytext and textdata packages
# Run: get_sentiments(lexicon = "nrc")
# Should be prompted to install lexicon - choose yes!
# Run: get_sentiments(lexicon = "afinn")
# Should be prompted to install lexicon - choose yes!

```

1) Practice Sentiment Analysis with Game of Thrones

## Your task

Taking this script as a point of departure, apply sentiment analysis on the Game of Thrones. You will find a pdf in the data folder. What are the most common meaningful words and what emotions do you expect will dominate this volume? Are there any terms that are similarly ambiguous to the 'confidence' above? 


we start by extracting the data from data file
```{r get-document}
got_path <- here("data","got.pdf")
got_text <- pdf_text(got_path)
```



## The task

Taking this script as a point of departure, apply sentiment analysis on the Game of Thrones. You will find a pdf in the data folder. What are the most common meaningful words and what emotions do you expect will dominate this volume? Are there any terms that are similarly ambiguous to the 'confidence' above? 

```{r split-lines}
got_df <- data.frame(got_text) %>% 
  mutate(text_full = str_split(got_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full)) 
```


```{r tokenize}
got_tokens <- got_df %>% 
  unnest_tokens(word, text_full)
```

```{r count-words}
got_wc <- got_tokens %>% 
  count(word) %>% 
  arrange(-n)
got_wc
```

```{r stopwords}
got_stop <- got_tokens %>% 
  anti_join(stop_words) %>% 
  select(-got_text)
```

```{r count-words2}
got_swc <- got_stop %>% 
  count(word) %>% 
  arrange(-n)
```

```{r skip-numbers}

got_no_numeric <- got_stop %>% 
  filter(is.na(as.numeric(word)))
```

```{r wordcloud-prep}
# There are almost 2000 unique words 
length(unique(got_no_numeric$word))

# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
got_top100 <- got_no_numeric %>% 
  count(word) %>% 
  arrange(-n) %>% 
  head(100)
```

```{r wordcloud}
got_cloud <- ggplot(data = got_top100, aes(label = word)) +
  geom_text_wordcloud() +
  theme_minimal()

got_cloud
```
```{r wordcloud-pro}
ggplot(data = got_top100, aes(label = word, size = n)) +
  geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
  scale_size_area(max_size = 12) +
  scale_color_gradientn(colors = c("darkgreen","blue","red")) +
  theme_minimal()
```
the most common unic word in the book is lord, considering lord is a title it is probably very fluid in the sentiments as the intended with the word can very alot depending on who uses it. 

lets se what some of the most negative and positive words are
```{r afinn}
get_sentiments(lexicon = "afinn")
# Note: may be prompted to download (yes)

# Let's look at the pretty positive words:
afinn_pos <- get_sentiments("afinn") %>% 
  filter(value %in% c(3,4,5))
afinn_neg <- get_sentiments("afinn") %>% 
  filter(value %in% c(-3,-4,-5))
# Do not look at negative words in class. 
afinn_neg
afinn_pos
```

```{r bing}
get_sentiments(lexicon = "bing")
```
```{r nrc}
get_sentiments(lexicon = "nrc")
```
```{r bind-afinn}
got_afinn <- got_stop %>% 
  inner_join(get_sentiments("afinn"))
```

Let's find some counts (by sentiment ranking):
```{r count-afinn}
got_afinn_hist <- got_afinn %>% 
  count(value)

# Plot them: 
ggplot(data = got_afinn_hist, aes(x = value, y = n)) +
  geom_col()
```

```{r afinn-2}
# What are these '2' words?
got_afinn_minus2 <- got_afinn %>% 
  filter(value == -2)
```



```{r afinn-2-more}
# Check the unique 2-score words:
unique(got_afinn_minus2$word)

# Count & plot them
got_afinn_minus2_n <- got_afinn_minus2 %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(factor(word), n))

got_plotting <- got_afinn_minus2_n[1:30, 1:2]
got_plotting

ggplot(data = got_plotting, aes(x = word, y = n)) +
  geom_col() +
  coord_flip()

# OK so what's the deal with confidence? And is it really "positive" in the emotion sense? 
```

```{r summarize-afinn}
got_summary <- got_afinn %>% 
  summarize(
    mean_score = mean(value),
    median_score = median(value)
     )
```


```{r bind-bing}
got_nrc <- got_stop %>% 
  inner_join(get_sentiments("nrc"))
```

```{r check-exclusions}
got_exclude <- got_stop %>% 
  anti_join(get_sentiments("nrc"))

# View(ipcc_exclude)

# Count to find the most excluded:
got_exclude_n <- got_exclude %>% 
  count(word, sort = TRUE)

head(got_exclude_n)
```

```{r count-bing}
got_nrc_n <- got_nrc %>% 
  count(sentiment, sort = TRUE)

# And plot them:

ggplot(data = got_nrc_n, aes(x = sentiment, y = n)) +
  geom_col()
```

lets filter to find the top five scoring words in each sentiment, remeber we are looking for "lord"
```{r count-nrc}
got_nrc_n5 <- got_nrc %>% 
  count(word,sentiment, sort = TRUE) %>% 
  group_by(sentiment) %>% 
  top_n(5) %>% 
  ungroup()

got_nrc_gg <- ggplot(data = got_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, ncol = 3, scales = "free") +
  coord_flip() +
  theme_minimal() +
  labs(x = "Word", y = "count")

# Show it
got_nrc_gg

# Save it
ggsave(plot = got_nrc_gg, 
       here("figures","got_nrc_sentiment.png"), 
       height = 8, 
       width = 5)

```
so lord comes up as negative, positive, trust, disgust lets check the word to see if this is the case
```{r nrc-confidence}
lord <- get_sentiments(lexicon = "nrc") %>% 
  filter(word == "lord")

# Yep, check it out:
lord
```

lord comming up as both disgust/trust and Negative/positive makes quite a bit of sense seeing as the word lord is a prestigious title, a title is often connected to wealthy person and therefor the word sentiment is very fluid considering it is abholdent to the person who uses it.



